<!DOCTYPE html>
<html>
    <head>
        <title>Gen AI</title>
        <style>
            .div1 {
                border: 5px outset palevioletred;
                text-align: center;
                background-color: aquamarine;
                height: 5%;
                width: 100%;
                color: rgb(101, 58, 72);
            }
            .div1 h1 {
                font-size: 46px;
            }
            .div2 {
                margin: 30px;
                p{margin: 30px; /* Adds space around the section */}
                .kp{margin: 30px; /* Adds space around the section */}
                
            }
            .arrow {
            list-style: none; /* Remove default bullets */
            }
            .arrow li::before {
                content: "➤ ";
                color: black;
                margin-right: 3px;
                padding-left: 0;
            }
            .a {
                text-align: center;
                border: 5px outset palevioletred;
            }
            /* .img {
            text-align: center;
            margin-top: 30px;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh; Full screen vertical centering
            } */
            .img{
                margin-left: 100px;
            }
        </style>
    </head>
    <body>
        <div class="div1">
            <h1>GENERATIVE AI</h1>
        </div>
        <div class="div2">
            <h1>✅What is GEN AI ?</h1>
            <p>Generative AI refers to a class of artificial intelligence systems designed to create new content — like text, images, music, videos, and more — that resembles what a human might produce.</p>
            <h3 class="kp">Key Points:</h3>
            <ul>
                <li>Instead of just recognizing patterns or making decisions, Generative AI generates new data based on what it has learned.</li>
                <li>It learns from a huge amount of existing data</li>
                <li>It can create original, realistic, and creative outputs.</li>
            </ul>
            <h1>✅ The Present and Future of AI is Generative :</h1>
            <h3 class="kp"> Present of AI: Generative AI is Already Transforming the World</h3>
            <ul>
                <li>Generative AI has become one of the most impactful breakthroughs in recent years.</li>
                <li>It has tools like ChatGPT, DALL·E, Midjourney, and GitHub Copilot, which are used in everyday tasks—from writing and coding to designing and creating content.</li>
                <li>It's Helping :</li>
            <ul class="arrow">
                <li>businesses automate workflows</li>
                <li>students learn faster</li>
                <li>artists create stunning visuals</li>
                <li>developers write better code</li>
            </ul>
                <li>In short, generative AI has made AI more accessible, creative, and interactive than ever before.</li>
            </ul>
            <h3 class="kp">🚀 Future of AI: Generative AI Will Lead the Next Wave of Innovation</h3>
            <p>Looking ahead, generative AI is expected to:</p>
            <ul>
            <!-- <p>Looking ahead, generative AI is expected to:</p> -->
                <li><b>Redefine industries</b> like healthcare (drug design, diagnosis), education (personalized tutoring), and media (content creation).</li>
                <li>Enable <b>hyper-personalized experiences</b> through smart virtual assistants and AI companions.</li>
                <li>Drive the evolution of <b>AI-powered creativity</b>, where humans collaborate with AI to co-create music, art, designs, and more.</li>
                <li>Play a key role in <b>autonomous systems</b>, like robots that can learn and adapt by generating simulations or actions.</li>
                <li>Continue to improve its <b>reasoning and decision-making abilities</b>, bringing us closer to artificial general intelligence (AGI).</li>
            </ul>
            <h1>✅ Latent Space</h1>
            <ul>
            <li><b>Latent</b>(hidden) <b>space</b> is a compressed, abstract representation of input data</li>
            <li>These Latent spaces are used for model training</li>
            <li>In generative AI (like autoencoders or GANs), data like images, text, or audio is transformed into a lower-dimensional space called the latent space.</li>
            <h4 class="a"><b>Input → [Encoder] → Latent Space → [Decoder] → Reconstructed Output</b></h4>
            <li><b>For example:</b></li>
            <h4 class="a">Original image → [Find and keep only the important details] → Hidden code that represents the image → [Turn the code back into an image] → Reconstructed image (almost like the original)</h4>
            </ul>
            <h1>✅ Representation Learning</h1>
            <ul>
            <li><b>Representation learning</b> is a technique where a model automatically learns useful features (representations) from raw data</li>
            <li>📦 In Simple Words:</li>
            <li>It’s like teaching a model to understand the data in its own language.</li>
            <li>Group the features of High dimentional space(ex. images) into a less dimentional space.</li>
            <h5>For example:</h5>
            <ul><li>Instead of telling the model “this is the edge of a cat,”</li>
            <li>We let it learn what "catness" looks like from thousands of examples.</li></ul>
            <h3>🔍 Types of Representations</h3>
            <div style="text-align: center">
             <table border="1" cellpadding="8" cellspacing="0" style="margin-left: 100px;">
                <tr>
                    <th>Type</th>
                    <th>Example</th>
                </tr>
                <tr>
                    <td>Images</td>
                    <td>From pixels → edges → shapes → objects</td>
                </tr>
                <tr>
                    <td>Text</td>
                    <td>From characters → words → semantic vectors</td>
                </tr>
                <tr>
                    <td>Audio</td>
                    <td>From waveforms → frequencies → spoken words</td>
                </tr>
             </table>
            </div>
            <h5>We have 3 Types of Representation Learning</h5>
            <ul><ul><li>1. Supervised Representation Learning</li>
            <li>2. Unsupervised Representation Learning</li>
            <li>3. Self-Supervised Learning</li></ul></ul>
           <table>
            <caption><h3>Representation Learning: Traditional ML vs Generative AI</h3></caption>
            <tr>
            <th>Feature</th>
            <th>Traditional Machine Learning (ML)</th>
            <th>Generative AI (GenAI)</th>
            </tr>
            <tr>
            <td><strong>Goal of Representation Learning</strong></td>
            <td>To extract useful features for prediction/classification tasks</td>
            <td>To <strong>generate new data</strong> by learning meaningful latent representations</td>
            </tr>
            <tr>
            <td><strong>How it's used</strong></td>
            <td>Helps models like SVM, Decision Trees, etc. perform better by using learned features</td>
            <td>Core to GenAI models like <strong>GANs, VAEs, Diffusion Models</strong> to create new content</td>
            </tr>
            <tr>
            <td><strong>Learning Type</strong></td>
            <td>Often <strong>supervised</strong> (learn representations using labels)</td>
            <td>Often <strong>unsupervised or self-supervised</strong> (learn from raw data without labels)</td>
            </tr>
            <tr>
            <td><strong>What it learns</strong></td>
            <td>Compact features (like edges, color, word frequency) that help with classification or regression</td>
            <td>Deep latent features (like "smile", "age", "style") that enable image/text generation and manipulation</td>
            </tr>
            <tr>
            <td><strong>Example Models</strong></td>
            <td>PCA, Autoencoders (for feature reduction); CNN layers in classifiers</td>
            <td>GANs (learn noise-to-image mapping), VAEs (learn smooth latent space), CLIP (joint image-text embeddings)</td>
            </tr>
            <tr>
            <td><strong>Output</strong></td>
            <td>Predictions, labels, clusters, or compressed features</td>
            <td>Realistic images, texts, videos, music, etc.</td>
            </tr>
            <tr>
            <td><strong>Use Case</strong></td>
            <td>Face recognition, document classification, customer segmentation</td>
            <td>Face generation, style transfer, image interpolation, AI art, text-to-image generation</td>
            </tr>
           </table>
           </ul>
    <h1>✅ The Battle Between Generator and Discriminator (In GANs)</h1>
    <ul>
    <h3>🧠 What is a GAN?</h3>
    <h5>A GAN (Generative Adversarial Network) consists of two neural networks:</h5>
    <ul>
    <li>🎨 Generator (G) – Tries to create fake data that looks real (like fake images, sounds, or text).</li>
    <li>🕵️‍♂️ Discriminator (D) – Tries to detect whether the input is real (from training data) or fake (from the generator).</li>
    </ul>
    <h3>🔁 How the Battle⚔️ Works (Step-by-Step)</h3>
    <li>Generator creates fake data (e.g., a fake image of a face).</li>

    <li>Discriminator receives both real and fake data and must guess which is which.</li>

    <li>Discriminator gives feedback (real or fake) to both the real data and the fake data.</li>

    <li>Generator uses that feedback to improve — it tries to fool the Discriminator better next time.</li>

    <li>Discriminator also improves — it learns better ways to tell fake from real.</li>

    <h3>🧠 What's the Goal?</h3>
    <li>🧑‍🎨 Generator's goal: Fool the Discriminator.</li>

    <li>👮‍♂️ Discriminator's goal: Catch the Generator's fakes.</li>

    <li>They compete in this adversarial game, and both get smarter over time.</li>

    <h3>🎯 End Result:</h3>
    <h5>When trained well:</h5>
    <li>The Generator produces data so realistic that the Discriminator can’t tell the difference.</li>
    <li> Model has learned to generate high-quality, realistic content.</li>
    </ul>
    <div class="img" ><img src="genai img1.png" alt="My Photo" width="500"></div>
    <h1>✅ What is Cross Entropy ?</h1>
    <ul>
    <h3>Cross Entropy is a loss function that measures the difference between the predicted output and the actual target in probabilistic terms.</h3>
        <li>It is widely used to train models like GANs, autoencoders, and language models by helping them learn to generate outputs closer to real data.</li>
        <li>It helps the <b>discriminator</b> learn to distinguish between real and fake data, and also helps the <b>generator</b> improve by trying to fool the discriminator.</li>
        <li>Cross entropy tells how bad your model's predictions are when compared to the true answers.</li>
        <ul>
            <li><b>Low cross-entropy = Good prediction</b></li>
            <li><b>cross-entropy = Bad prediction</b></li>
        </ul>
        <li>It is used to minimize the loss, and making realistic predictions or generating real-like data.</li>
    </ul>
    <h3>Example:</h3>
    <ul>
        <li>Imagine a model is trying to <b>predict whether an image is real (1) or fake (0)</b>.</li>
        <ul>
            <li><b>True Label = 1</b>(real image)</li>
            <li><b>Predicted Probability = 0.9</b>(model is 90% confident it's real)</li>
        </ul>
        <li>Cross Entropy Formula (Binary):</li>
        <h3>Loss=−[y⋅log(p)+(1−y)⋅log(1−p)]</h3>
        <li>Now plug in the values:</li>
        <h3>Loss=−[1⋅log(0.9)+(1−1)⋅log(1−0.9)]</h3>
        <h3>Loss=−log(0.9)=0.105</h3>
        <li>Small loss = Good prediction!</li>
    </ul>
</div>

    </body>
</html>